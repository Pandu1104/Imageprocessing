{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12214871,"sourceType":"datasetVersion","datasetId":7695163},{"sourceId":12229543,"sourceType":"datasetVersion","datasetId":7705364},{"sourceId":12240241,"sourceType":"datasetVersion","datasetId":7712405}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:53:39.643783Z","iopub.execute_input":"2025-06-19T07:53:39.644107Z","iopub.status.idle":"2025-06-19T07:53:47.494244Z","shell.execute_reply.started":"2025-06-19T07:53:39.644084Z","shell.execute_reply":"2025-06-19T07:53:47.493447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For progress bar\n!pip install tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:53:47.495650Z","iopub.execute_input":"2025-06-19T07:53:47.495995Z","iopub.status.idle":"2025-06-19T07:53:50.559233Z","shell.execute_reply.started":"2025-06-19T07:53:47.495972Z","shell.execute_reply":"2025-06-19T07:53:50.558434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:53:50.560284Z","iopub.execute_input":"2025-06-19T07:53:50.560562Z","iopub.status.idle":"2025-06-19T07:53:50.565489Z","shell.execute_reply.started":"2025-06-19T07:53:50.560536Z","shell.execute_reply":"2025-06-19T07:53:50.564765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SRDataset(Dataset):\n    def __init__(self, lr_dir, hr_dir, transform=None):\n        self.lr_paths = sorted([os.path.join(lr_dir, f) for f in os.listdir(lr_dir)])\n        self.hr_paths = sorted([os.path.join(hr_dir, f) for f in os.listdir(hr_dir)])\n        self.transform = transform or transforms.ToTensor()\n\n    def __len__(self):\n        return len(self.lr_paths)\n\n    def __getitem__(self, idx):\n        lr = Image.open(self.lr_paths[idx]).convert(\"RGB\")\n        hr = Image.open(self.hr_paths[idx]).convert(\"RGB\")\n        return self.transform(lr), self.transform(hr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:53:50.567007Z","iopub.execute_input":"2025-06-19T07:53:50.567479Z","iopub.status.idle":"2025-06-19T07:53:50.589722Z","shell.execute_reply.started":"2025-06-19T07:53:50.567460Z","shell.execute_reply":"2025-06-19T07:53:50.589207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        def CBR(in_channels, out_channels):\n            return nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n                nn.BatchNorm2d(out_channels),\n                nn.ReLU(inplace=True),\n            )\n\n        self.enc1 = CBR(3, 64)\n        self.enc2 = CBR(64, 128)\n        self.enc3 = CBR(128, 256)\n        self.pool = nn.MaxPool2d(2)\n\n        self.dec3 = CBR(256, 128)\n        self.dec2 = CBR(128, 64)\n        self.final = nn.Conv2d(64, 3, 1)\n\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n\n    def forward(self, x):\n        x1 = self.enc1(x)                      # 256x256 → 256x256\n        x2 = self.enc2(self.pool(x1))          # 256x256 → 128x128\n        x3 = self.enc3(self.pool(x2))          # 128x128 → 64x64\n\n        x = self.upsample(x3)                  # 64x64 → 128x128\n        x = self.dec3(x)                       # → 128x128\n\n        x = self.upsample(x)                   # 128x128 → 256x256\n        x = self.dec2(x)                       # → 256x256\n\n        x = self.final(x)                      # final output: 256x256\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:58:34.141605Z","iopub.execute_input":"2025-06-19T07:58:34.141876Z","iopub.status.idle":"2025-06-19T07:58:34.148542Z","shell.execute_reply.started":"2025-06-19T07:58:34.141858Z","shell.execute_reply":"2025-06-19T07:58:34.147776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 16\nPATCH_SIZE = 256\n\ntrain_dataset = SRDataset(\n    lr_dir=\"/kaggle/input/intel-dataset/dataset/train/LR\",\n    hr_dir=\"/kaggle/input/intel-dataset/dataset/train/HR\"\n)\n\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:58:38.784401Z","iopub.execute_input":"2025-06-19T07:58:38.784666Z","iopub.status.idle":"2025-06-19T07:58:38.805962Z","shell.execute_reply.started":"2025-06-19T07:58:38.784646Z","shell.execute_reply":"2025-06-19T07:58:38.805429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = UNet().to(device)\ncriterion = nn.L1Loss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:58:42.286879Z","iopub.execute_input":"2025-06-19T07:58:42.287623Z","iopub.status.idle":"2025-06-19T07:58:42.305392Z","shell.execute_reply.started":"2025-06-19T07:58:42.287591Z","shell.execute_reply":"2025-06-19T07:58:42.304671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 10  # Change as needed\n\nfor epoch in range(EPOCHS):\n    model.train()\n    epoch_loss = 0\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n\n    for lr, hr in loop:\n        lr, hr = lr.to(device), hr.to(device)\n\n        output = model(lr)\n        loss = criterion(output, hr)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n\n    print(f\"Epoch {epoch+1} Loss: {epoch_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:58:46.426332Z","iopub.execute_input":"2025-06-19T07:58:46.427007Z","iopub.status.idle":"2025-06-19T08:13:54.280130Z","shell.execute_reply.started":"2025-06-19T07:58:46.426976Z","shell.execute_reply":"2025-06-19T08:13:54.279331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"unet_sr.pth\")\nprint(\"✅ Model saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T08:14:26.153805Z","iopub.execute_input":"2025-06-19T08:14:26.154510Z","iopub.status.idle":"2025-06-19T08:14:26.181005Z","shell.execute_reply.started":"2025-06-19T08:14:26.154485Z","shell.execute_reply":"2025-06-19T08:14:26.180240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\n\n# --- UNet Model ---\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(inplace=True)\n        )\n        self.middle = nn.Sequential(\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(inplace=True)\n        )\n        self.decoder = nn.Sequential(\n            nn.Conv2d(64, 3, 3, padding=1), nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.middle(x)\n        x = self.decoder(x)\n        return x\n\n# --- Dataset ---\nclass DistillationDataset(Dataset):\n    def __init__(self, lr_dir, hr_dir, teacher_dir):\n        self.lr_paths = sorted([os.path.join(lr_dir, f) for f in os.listdir(lr_dir) if f.endswith('.png')])\n        self.hr_paths = sorted([os.path.join(hr_dir, f) for f in os.listdir(hr_dir) if f.endswith('.png')])\n        self.teacher_paths = sorted([os.path.join(teacher_dir, f) for f in os.listdir(teacher_dir) if f.endswith('.png')])\n        self.transform = transforms.ToTensor()\n\n    def __len__(self):\n        return len(self.lr_paths)\n\n    def __getitem__(self, idx):\n        lr = self.transform(Image.open(self.lr_paths[idx]).convert(\"RGB\"))\n        hr = self.transform(Image.open(self.hr_paths[idx]).convert(\"RGB\"))\n        teacher = self.transform(Image.open(self.teacher_paths[idx]).convert(\"RGB\"))\n        return lr, hr, teacher\n\n# --- Training Function ---\ndef train_model():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # ✅ CHANGE THESE PATHS TO YOUR DATASET NAMES\n    lr_dir=\"/kaggle/input/intel-dataset/dataset/train/LR\"\n    hr_dir=\"/kaggle/input/intel-dataset/dataset/train/HR\"\n    teacher_dir = \"/kaggle/input/d/lohithakakumani/teacher-output/teacher_resized\"\n\n    dataset = DistillationDataset(lr_dir, hr_dir, teacher_dir)\n    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n    model = UNet().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    l1_loss = nn.L1Loss()\n\n    # You can adjust weights for pixel and distillation losses\n    alpha = 1.0   # weight for pixel loss\n    beta = 0.5    # weight for distillation loss\n\n    num_epochs = 15\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        for lr, hr, teacher in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            lr, hr, teacher = lr.to(device), hr.to(device), teacher.to(device)\n\n            output = model(lr)\n            pixel_loss = l1_loss(output, hr)\n            distill_loss = l1_loss(output, teacher)\n            loss = alpha * pixel_loss + beta * distill_loss\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n\n    torch.save(model.state_dict(), \"distilled_unet.pth\")\n    print(\"✅ Student model with distillation saved as 'distilled_unet.pth'\")\n\n# --- Run the training ---\nif __name__ == \"__main__\":\n    train_model()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\n\n# --- UNet Model ---\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(inplace=True)\n        )\n        self.middle = nn.Sequential(\n            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(inplace=True),\n            nn.Conv2d(128, 64, 3, padding=1), nn.ReLU(inplace=True)\n        )\n        self.decoder = nn.Sequential(\n            nn.Conv2d(64, 3, 3, padding=1), nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.middle(x)\n        x = self.decoder(x)\n        return x\n\n# --- Dataset ---\nclass DistillationDataset(Dataset):\n    def __init__(self, lr_dir, hr_dir, teacher_dir):\n        self.lr_paths = sorted([os.path.join(lr_dir, f) for f in os.listdir(lr_dir) if f.endswith('.png')])\n        self.hr_paths = sorted([os.path.join(hr_dir, f) for f in os.listdir(hr_dir) if f.endswith('.png')])\n        self.teacher_paths = sorted([os.path.join(teacher_dir, f) for f in os.listdir(teacher_dir) if f.endswith('.png')])\n        self.transform = transforms.ToTensor()\n\n    def __len__(self):\n        return len(self.lr_paths)\n\n    def __getitem__(self, idx):\n        lr = self.transform(Image.open(self.lr_paths[idx]).convert(\"RGB\"))\n        hr = self.transform(Image.open(self.hr_paths[idx]).convert(\"RGB\"))\n        teacher = self.transform(Image.open(self.teacher_paths[idx]).convert(\"RGB\"))\n        return lr, hr, teacher\n\n# --- Training Function ---\ndef train_model():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # ✅ CHANGE THESE PATHS TO YOUR DATASET NAMES\n    lr_dir=\"/kaggle/input/intel-dataset/dataset/train/LR\"\n    hr_dir=\"/kaggle/input/intel-dataset/dataset/train/HR\"\n    teacher_dir = \"/kaggle/input/d/lohithakakumani/teacher-output/teacher_resized\"\n\n    dataset = DistillationDataset(lr_dir, hr_dir, teacher_dir)\n    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n    model = UNet().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n    l1_loss = nn.L1Loss()\n\n    # You can adjust weights for pixel and distillation losses\n    alpha = 1.0   # weight for pixel loss\n    beta = 0.5    # weight for distillation loss\n\n    num_epochs = 15\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        for lr, hr, teacher in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            lr, hr, teacher = lr.to(device), hr.to(device), teacher.to(device)\n\n            output = model(lr)\n            pixel_loss = l1_loss(output, hr)\n            distill_loss = l1_loss(output, teacher)\n            loss = alpha * pixel_loss + beta * distill_loss\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n\n    torch.save(model.state_dict(), \"distilled_unet.pth\")\n    print(\"✅ Student model with distillation saved as 'distilled_unet.pth'\")\n\n# --- Run the training ---\nif __name__ == \"__main__\":\n    train_model()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T18:21:34.942219Z","iopub.execute_input":"2025-06-21T18:21:34.943130Z","iopub.status.idle":"2025-06-21T18:48:22.568068Z","shell.execute_reply.started":"2025-06-21T18:21:34.943101Z","shell.execute_reply":"2025-06-21T18:48:22.567303Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/15: 100%|██████████| 100/100 [01:55<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.2292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.0732\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|██████████| 100/100 [01:46<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.0652\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|██████████| 100/100 [01:47<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.0577\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|██████████| 100/100 [01:46<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.0507\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|██████████| 100/100 [01:46<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 0.0490\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|██████████| 100/100 [01:47<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 0.0483\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|██████████| 100/100 [01:47<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 0.0463\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|██████████| 100/100 [01:46<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 0.0449\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|██████████| 100/100 [01:46<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 0.0447\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|██████████| 100/100 [01:45<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11, Loss: 0.0426\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|██████████| 100/100 [01:46<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12, Loss: 0.0433\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|██████████| 100/100 [01:46<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13, Loss: 0.0417\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|██████████| 100/100 [01:46<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14, Loss: 0.0412\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|██████████| 100/100 [01:47<00:00,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 15, Loss: 0.0406\n✅ Student model with distillation saved as 'distilled_unet.pth'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4}]}